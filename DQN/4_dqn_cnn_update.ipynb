{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c09ada11-d3a6-4837-b4d0-9657106a54b5",
   "metadata": {},
   "source": [
    "# Deep Q-Network (DQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34722639-6c01-4c5b-ab65-c8d5cb2adaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torchinfo import summary\n",
    "\n",
    "import ale_py\n",
    "import gymnasium as gym\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./dqn\") \n",
    "import evaluation\n",
    "from atari_env import make_env\n",
    "from q_network import CNNQNetwork\n",
    "from dqn_cnn import run_dqn\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6a7e12",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "429b73a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0.0, 1.0, (4, 84, 84), float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_id = \"ALE/Breakout-v5\"\n",
    "env = make_env(env_id, render_mode=\"rgb_array\")\n",
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc3c1b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying frame shifts:\n",
      "Frame 0 of second step should equal Frame 1 of first step: True\n",
      "Frame 1 of second step should equal Frame 2 of first step: True\n",
      "Frame 2 of second step should equal Frame 3 of first step: True\n",
      "New frame in second step should be different from all previous: True\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "obs, _ = env.reset()\n",
    "\n",
    "# Take first step\n",
    "obs1, _, _, _, _ = env.step(env.action_space.sample())\n",
    "\n",
    "# Take second step\n",
    "obs2, _, _, _, _ = env.step(env.action_space.sample())\n",
    "\n",
    "# Create a side-by-side plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))  # 1 row, 2 columns\n",
    "\n",
    "# Display first frame (obs1[-1])\n",
    "axes[0].imshow(obs1[-1], cmap='gray')\n",
    "axes[0].set_title(\"After First Step\")\n",
    "axes[0].axis('off')  # Hide axes for cleaner look\n",
    "\n",
    "# Display second frame (obs2[-1])\n",
    "axes[1].imshow(obs2[-1], cmap='gray')\n",
    "axes[1].set_title(\"After Second Step\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()  # Adjust spacing between subplots\n",
    "plt.show()\n",
    "\n",
    "# Verify frames have shifted\n",
    "print(\"\\nVerifying frame shifts:\")\n",
    "print(f\"Frame 0 of second step should equal Frame 1 of first step: {np.allclose(obs2[0], obs1[1])}\")\n",
    "print(f\"Frame 1 of second step should equal Frame 2 of first step: {np.allclose(obs2[1], obs1[2])}\")\n",
    "print(f\"Frame 2 of second step should equal Frame 3 of first step: {np.allclose(obs2[2], obs1[3])}\")\n",
    "print(f\"New frame in second step should be different from all previous: {not np.any(np.allclose(obs2[3], obs1, atol=0.1))}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12adc3f2",
   "metadata": {},
   "source": [
    "## Q-Network with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14164c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Summary for input shape: (1, 4, 84, 84)\n",
      "=====================================================================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape              Mult-Adds\n",
      "=====================================================================================================================================================================\n",
      "CNNQNetwork                              [1, 4, 84, 84]            [1, 6]                    --                        --                        --\n",
      "├─Sequential: 1-1                        [1, 4, 84, 84]            [1, 6]                    --                        --                        --\n",
      "│    └─Conv2d: 2-1                       [1, 4, 84, 84]            [1, 32, 20, 20]           8,224                     [8, 8]                    3,289,600\n",
      "│    └─ReLU: 2-2                         [1, 32, 20, 20]           [1, 32, 20, 20]           --                        --                        --\n",
      "│    └─Conv2d: 2-3                       [1, 32, 20, 20]           [1, 64, 9, 9]             32,832                    [4, 4]                    2,659,392\n",
      "│    └─ReLU: 2-4                         [1, 64, 9, 9]             [1, 64, 9, 9]             --                        --                        --\n",
      "│    └─Conv2d: 2-5                       [1, 64, 9, 9]             [1, 64, 7, 7]             36,928                    [3, 3]                    1,809,472\n",
      "│    └─ReLU: 2-6                         [1, 64, 7, 7]             [1, 64, 7, 7]             --                        --                        --\n",
      "│    └─Flatten: 2-7                      [1, 64, 7, 7]             [1, 3136]                 --                        --                        --\n",
      "│    └─Linear: 2-8                       [1, 3136]                 [1, 512]                  1,606,144                 --                        1,606,144\n",
      "│    └─ReLU: 2-9                         [1, 512]                  [1, 512]                  --                        --                        --\n",
      "│    └─Linear: 2-10                      [1, 512]                  [1, 6]                    3,078                     --                        3,078\n",
      "=====================================================================================================================================================================\n",
      "Total params: 1,687,206\n",
      "Trainable params: 1,687,206\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 9.37\n",
      "=====================================================================================================================================================================\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 0.17\n",
      "Params size (MB): 6.75\n",
      "Estimated Total Size (MB): 7.03\n",
      "=====================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "env_id = \"ALE/Pong-v5\"\n",
    "env = make_env(env_id, render_mode=\"rgb_array\")\n",
    "\n",
    "obs, _ = env.reset()\n",
    "q_net = CNNQNetwork(env.observation_space, env.action_space)\n",
    "\n",
    "# Get the correct input shape from the environment\n",
    "input_shape = env.observation_space.shape\n",
    "\n",
    "# Print model summary with correct input shape\n",
    "print(f\"\\nModel Summary for input shape: {(1,) + input_shape}\")\n",
    "model_summary = summary(\n",
    "    q_net,\n",
    "    input_size=(1,) + input_shape,  # Add batch dimension\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"],\n",
    "    verbose=0\n",
    ")\n",
    "print(model_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14af9427-8166-40fa-a581-51599d3be306",
   "metadata": {},
   "source": [
    "## Train DQN agent with target network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8c390a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "env_id = \"ALE/Pong-v5\"\n",
    "# when in cpu, around 35mins\n",
    "q_net = run_dqn(\n",
    "    env_id= env_id,\n",
    "    n_timesteps=1000_000,     # \n",
    "    learning_starts=5_000,     # later learning starts\n",
    "    exploration_fraction=0.5, # slower decay over 50% of timesteps\n",
    "    replay_buffer_size=100_000,\n",
    "    learning_rate=5e-4,\n",
    "    batch_size=128,\n",
    "    update_interval = 4,\n",
    "    target_network_update_interval=1000,\n",
    "    evaluation_interval=100_000,\n",
    "    gamma=0.99,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52450a1f-60b4-4098-bc64-5860476a50cc",
   "metadata": {},
   "source": [
    "### Visualize the trained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56e18bf9-e3e4-495d-be4b-6acf0ae28ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean episode reward: -14.50 +/- 0.50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-14.5, 0.5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "eval_env = make_env(\"ALE/Pong-v5\", render_mode=\"rgb_array\")\n",
    "n_eval_episodes = 2\n",
    "eval_exploration_rate = 0.0\n",
    "video_name = f\"DQN_pong\"\n",
    "\n",
    "# Optional: load checkpoint\n",
    "q_net = CNNQNetwork(env.observation_space, env.action_space)\n",
    "q_net.load_state_dict(torch.load(\"./logs/q_net_checkpoint_ALE_Pong-v5_100000.pth\"))\n",
    "\n",
    "evaluation.evaluate_policy(\n",
    "    eval_env,\n",
    "    q_net,\n",
    "    n_eval_episodes,\n",
    "    eval_exploration_rate=eval_exploration_rate,\n",
    "    video_name=video_name,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642e02d8-bd9c-4a07-9a0d-86748dcdd391",
   "metadata": {},
   "source": [
    "## Training DQN agent on flappy bird:\n",
    "\n",
    "You can go in the [GitHub repo](https://github.com/araffin/flappy-bird-gymnasium/tree/patch-1) to learn more about this environment.\n",
    "\n",
    "<div>\n",
    "    <img src=\"https://raw.githubusercontent.com/markub3327/flappy-bird-gymnasium/main/imgs/dqn.gif\" width=\"300\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e9703d-7b5b-4188-9737-786476a627ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"flappy-bird-gymnasium @ git+https://github.com/araffin/flappy-bird-gymnasium@patch-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a0eef2-d652-4224-86c6-8f669e82ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flappy_bird_gymnasium  # noqa: F401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf79677e-561c-4bb5-95d2-d4a99eb0579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"FlappyBird-v0\"\n",
    "\n",
    "q_net = run_dqn(\n",
    "    env_id=env_id,\n",
    "    replay_buffer_size=100_000,\n",
    "    # Note: you can remove the target network\n",
    "    # by setting target_network_update_interval=1\n",
    "    target_network_update_interval=250,\n",
    "    learning_starts=10_000,\n",
    "    exploration_initial_eps=1.0,\n",
    "    exploration_final_eps=0.03,\n",
    "    exploration_fraction=0.1,\n",
    "    n_timesteps=500_000,\n",
    "    update_interval=4,\n",
    "    learning_rate=1e-3,\n",
    "    batch_size=128,\n",
    "    gamma=0.98,\n",
    "    n_eval_episodes=5,\n",
    "    evaluation_interval=50000,\n",
    "    n_hidden_units=256,\n",
    "    # No exploration during evaluation\n",
    "    # (deteministic policy)\n",
    "    eval_exploration_rate=0.0,\n",
    "    seed=2023,\n",
    "    eval_render_mode=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a08cc96-2601-49dc-921c-44e2a048df81",
   "metadata": {},
   "source": [
    "### Record a video of the trained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e191f2-e3b3-41d0-bff2-50e1b9c9d19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_env = gym.make(env_id, render_mode=\"rgb_array\")\n",
    "n_eval_episodes = 3\n",
    "eval_exploration_rate = 0.00\n",
    "video_name = f\"DQN_{env_id}\"\n",
    "\n",
    "\n",
    "# Optional: load checkpoint\n",
    "q_net = QNetwork(eval_env.observation_space, eval_env.action_space, n_hidden_units=256)\n",
    "# Convert weights from float32 to float64 to match flappy bird obs\n",
    "q_net.double()\n",
    "q_net.load_state_dict(th.load(\"../logs/q_net_checkpoint_FlappyBird-v0_200000.pth\"))\n",
    "\n",
    "evaluation.evaluate_policy(\n",
    "    eval_env,\n",
    "    q_net,\n",
    "    n_eval_episodes,\n",
    "    eval_exploration_rate=eval_exploration_rate,\n",
    "    video_name=video_name,\n",
    ")\n",
    "\n",
    "show_videos(video_folder, prefix=video_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a60230-6477-4318-8d60-10f6eada6064",
   "metadata": {},
   "source": [
    "### Going further\n",
    "\n",
    "- analyse the learned q-values\n",
    "- explore different value for the target update, use soft update instead of hard-copy\n",
    "- experiment with Huber loss (smooth l1 loss) instead of l2 loss (mean squared error)\n",
    "- play with different environments\n",
    "- implement a CNN to play flappybird/pong from pixels (need to stack frames)\n",
    "- implement DQN extensions (double Q-learning, prioritized experience replay, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be2cc11-79e6-40c6-ab61-f78fec498315",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, you have seen how to implement the DQN algorithm (update rule and training loop) using all the components from part I (replay buffer, epsilon-greedy exploration strategy, Q-Network, ...)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l2rpn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
